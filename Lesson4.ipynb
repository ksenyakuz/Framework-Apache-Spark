{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "Mruxmbsjk38S",
        "outputId": "c79b164f-c97e-4d9a-880f-a2a4044f292b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=bb30ef5f9415aea4066481b1fcbc661814d5f565a5dd982e24665b5e4a34ec23\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Q9g_UyNxS6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "    .master(\"local[2]\")\\\n",
        "    .appName(\"Lesson_4\")\\\n",
        "    .config(\"spark.executor.instances\",2)\\\n",
        "    .config(\"spark.executor.memory\",'2g')\\\n",
        "    .config(\"spark.executor.cores\",1)\\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVGNGR7pN1KC"
      },
      "source": [
        "# Самостоятельная работа к уроку 4\n",
        "На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agigNChqOHnK"
      },
      "source": [
        "## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\n",
        "\n",
        " Каждая строчка это продажа жилья, которая состоит из следующих полей (думаю описание не требуется):\n",
        "*   date of sale\n",
        "*   price\n",
        "*   property type\n",
        "*   number of bedrooms\n",
        "*   4digit postcode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as F \n",
        "from pyspark.sql.pandas.functions import pandas_udf, PandasUDFType\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "import pandas as pd\n",
        "import requests"
      ],
      "metadata": {
        "id": "b9Zdeye7lf1h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_response = requests.get('https://drive.google.com/uc?id=1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp')\n",
        "with open('raw_sales.csv', 'wb') as file:\n",
        "    file.write(train_response.content)\n",
        "data = spark.read.csv('raw_sales.csv', header=True, inferSchema=True)\n",
        "data.show(5)\n",
        "data.printSchema()"
      ],
      "metadata": {
        "id": "ZW2_ENIiljly",
        "outputId": "b45e6cf9-ff71-4820-b2b0-69ef9f2cf66b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+------+------------+--------+\n",
            "|           datesold|postcode| price|propertyType|bedrooms|\n",
            "+-------------------+--------+------+------------+--------+\n",
            "|2007-02-07 00:00:00|    2607|525000|       house|       4|\n",
            "|2007-02-27 00:00:00|    2906|290000|       house|       3|\n",
            "|2007-03-07 00:00:00|    2905|328000|       house|       3|\n",
            "|2007-03-09 00:00:00|    2905|380000|       house|       4|\n",
            "|2007-03-21 00:00:00|    2906|310000|       house|       3|\n",
            "+-------------------+--------+------+------------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- datesold: timestamp (nullable = true)\n",
            " |-- postcode: integer (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            " |-- propertyType: string (nullable = true)\n",
            " |-- bedrooms: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xisyFowtQgx-"
      },
      "source": [
        "## Задание 1\n",
        "Добавьте к таблице следующие поля:\n",
        "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode)\n",
        "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\n",
        "*  Стоимость последнего проданного дома до текущего\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window = Window.partitionBy('postcode').orderBy('datesold')\n",
        "\n",
        "df = (\n",
        "    data.withColumn('avg_price_before_sale', F.avg(F.col('price'))\n",
        "    .over(window.rowsBetween(Window.currentRow-10, Window.currentRow-1)))\n",
        ")\n",
        "\n",
        "df = (\n",
        "    df.withColumn('avg_price_after_sale', F.avg(F.col('price'))\n",
        "    .over(window.rowsBetween(Window.currentRow+1, Window.currentRow+10)))\n",
        ")\n",
        "\n",
        "df = df.withColumn('last_price_before_sale', F.lag(F.col('price'), 1).over(window))\n",
        "\n",
        "df = df.filter(F.col('propertyType') == 'house')\n",
        "\n",
        "df = df.selectExpr('datesold', 'postcode', 'price', 'propertyType', 'bedrooms',\n",
        "                   'cast(avg_price_before_sale as int) as avg_price_before_sale', \n",
        "                   'cast(avg_price_after_sale as int) as avg_price_after_sale',\n",
        "                   'last_price_before_sale')\n",
        "\n",
        "(\n",
        "    df.filter(F.col('avg_price_before_sale').isNotNull())\n",
        "    .select('*').orderBy('postcode', 'datesold').show(10)\n",
        ")"
      ],
      "metadata": {
        "id": "EZh-TmEPmCEu",
        "outputId": "b496e154-50fd-4ddf-83fa-4333d0121aff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvh2x6_8YU3F"
      },
      "source": [
        "## Задание 2\n",
        "В итоге у вас таблица с колонками (или нечто похожее):\n",
        "*   price\n",
        "*   Среднегодовая цена\n",
        "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
        "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
        "*  Стоимость последнего проданного дома до текущего ((1 балл)\n",
        "*  и др.\n",
        "\n",
        "Посчитайте кол-во уникальных значений в каждой строчке (unique(row)) (ипользуйте udf). Попробуйте сделать то же самое используя pandas udf."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@F.udf(returnType=IntegerType())\n",
        "def count_unique_udf(row):\n",
        "    return len(set(row))\n",
        "(\n",
        "    df.filter(F.col('avg_price_before_sale').isNotNull())\n",
        "    .withColumn('unique_values', count_unique_udf(F.array(*df))).show(10)\n",
        ")"
      ],
      "metadata": {
        "id": "90nNs8oAmQg2",
        "outputId": "4c98887d-3f44-4b08-95e0-382618068a54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|unique_values|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|            7|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|            8|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|            8|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|            8|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|            8|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|            8|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|            8|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|            8|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|            8|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|            8|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@pandas_udf(IntegerType(), PandasUDFType.SCALAR)\n",
        "def count_unique_pandas_udf(series) -> int:\n",
        "    return series.apply(lambda row: len(set(row)))\n",
        "(\n",
        "    df.filter(F.col('avg_price_before_sale').isNotNull())\n",
        "    .withColumn('unique_values', count_unique_pandas_udf(F.array(*df))).show(10)\n",
        ")"
      ],
      "metadata": {
        "id": "2RTAK2dxmVq6",
        "outputId": "517c7070-4f51-4106-9d27-7d91e67cf230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/functions.py:399: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|unique_values|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|            7|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|            8|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|            8|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|            8|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|            8|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|            8|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|            8|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|            8|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|            8|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|            8|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSZTI9PAwQb"
      },
      "source": [
        "# Задание 3\n",
        "SQL like case when или if elif else\n",
        "\n",
        "Создайте колонку, в которой в которой будет отображаться \"+\", \"-\" или \"=\", если \"Средняя стомость 10 проданных домов до текущего в том же районе\" больше, меньше или равно \"Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\", соотвественно.\n",
        "\n",
        "Если одно из полей Null, запишите в эту колонку \"Нет данных\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3pfUThFQtE6",
        "outputId": "1df98717-4dc4-4180-96e2-6db3377fa358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = df.withColumn(\n",
        "    'sign',\n",
        "    F.when(\n",
        "        F.col('avg_price_before_sale').isNull() | \n",
        "        F.col('avg_price_after_sale').isNull(),\n",
        "        'Нет данных'\n",
        "    ).when(\n",
        "        F.col('avg_price_before_sale') > F.col('avg_price_after_sale'),\n",
        "        '-'\n",
        "    ).when(\n",
        "        F.col('avg_price_before_sale') < F.col('avg_price_after_sale'),\n",
        "        '+'\n",
        "    ).otherwise(\n",
        "        '='\n",
        "    )\n",
        ")\n",
        "\n",
        "df.show()     "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|      sign|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\n",
            "|2007-07-08 00:00:00|    2600| 327000|       house|       1|                 null|              708350|                  null|Нет данных|\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|         +|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|         +|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|         +|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|         +|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|         +|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|         +|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|         +|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|         +|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|         +|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|         +|\n",
            "|2008-11-18 00:00:00|    2600| 950000|       house|       3|               679350|              701050|                635000|         +|\n",
            "|2008-11-21 00:00:00|    2600| 730000|       house|       3|               742850|              729550|                950000|         -|\n",
            "|2008-12-22 00:00:00|    2600| 855000|       house|       3|               786600|              716250|                730000|         -|\n",
            "|2008-12-24 00:00:00|    2600|1057500|       house|       4|               839200|              641500|                855000|         -|\n",
            "|2009-01-20 00:00:00|    2600|1150000|       house|       4|               715250|              641500|                475000|         -|\n",
            "|2009-01-22 00:00:00|    2600| 575000|       house|       3|               756250|              684000|               1150000|         -|\n",
            "|2009-02-13 00:00:00|    2600| 880000|       house|       4|               730550|              690700|                578000|         -|\n",
            "|2009-03-17 00:00:00|    2600|1015000|       house|       4|               701050|              735200|                410000|         +|\n",
            "|2009-03-28 00:00:00|    2600| 722000|       house|       4|               729550|              744000|               1015000|         +|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9BVAzQimd8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}